{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skspatial.objects import Points, Plane\n",
    "from skspatial.plotting import plot_3d\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "img_name = \"../data/Plant_holder.jpg\"\n",
    "\n",
    "def reader(name): #OK\n",
    "     #load\n",
    "    img = cv2.imread(name)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img, plot = False): #OK\n",
    "    \n",
    "    \"\"\"Finds object(several to handle to be defined) in frame \"\"\"\n",
    "    \n",
    "    #smoothen\n",
    "    img = cv2.medianBlur(img,5)\n",
    "\n",
    "    #resize\n",
    "    scale = 0.1\n",
    "    new_height = int(img.shape[0]*scale)\n",
    "    new_width  = int(img.shape[1]*scale)\n",
    "    img = cv2.resize(img, (new_width, new_height),interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    #define BGR orange color range for BGR thresholding\n",
    "    l_orange = np.array([10,50,175],dtype = np.float32)\n",
    "    u_orange = np.array([40,73,210],dtype = np.float32)\n",
    "    \n",
    "    #opening to get rid of the small background artifacts\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    \n",
    "    #thresholding and open\n",
    "    mask = cv2.inRange(img, l_orange, u_orange)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    if plot:\n",
    "        #bitwise and mask and original picture\n",
    "        res = cv2.bitwise_and(img,img, mask= mask)\n",
    "        cv2.imshow('result',res)\n",
    "        cv2.imshow('mask BGR',mask)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return mask, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reader(img_name)\n",
    "mask, img = get_mask(img, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans\n",
    "clust = img.reshape((-1,3))\n",
    "clust = np.float32(clust) #should be flattened and of type float32\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10,1.0) #max iter and accuracy epsilon\n",
    "K = 3 #2 clusters\n",
    "ret, label, center = cv2.kmeans(clust, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "clust = res.reshape((img.shape))\n",
    "    \n",
    "# Print\n",
    "#cv2.imshow('K-means',clust)\n",
    "#cv2.imshow('Original', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Convert to hsv format\n",
    "#hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define orange color range for HSV thresholding\n",
    "#low_orange = np.array([5,211,186],dtype = np.float32)\n",
    "#upp_orange = np.array([6.5,255,255],dtype = np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create trackcolourbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(img, mask, verbose = False): #OK\n",
    "    \"\"\"Returns centroid in image coordinates\n",
    "        Args: 2D image (3 channels RGB)\n",
    "              mask (1/0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find moments based on contours\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    threshold = 200  \n",
    "    contours = [el for el in contours if cv2.contourArea(el) > threshold]\n",
    "    cnt = contours[0]\n",
    "    M = cv2.moments(cnt)\n",
    "\n",
    "    # Find centroid\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    # Plots\n",
    "    if verbose:\n",
    "        # Centroid pixels coordinates\n",
    "        print(\"x : {}, y : {}\".format(cx,cy))\n",
    "        # Print centroid\n",
    "        cv2.circle(img, (int(cx),int(cy)), 2, 255, 2)\n",
    "        # Draw contours\n",
    "        cv2.drawContours(img, contours, -1, (255, 0, 0), 2) # image, contours, contourIdx, color, thickness\n",
    "        cv2.imshow('centroid',img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    return [cx, cy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get object orientation (3D normal vector)\n",
    "https://www.ilikebigbits.com/2015_03_04_plane_from_points.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plane_orientation(mask, img, depth): #is depth included in the image ? #TO TEST\n",
    "    \"\"\"\n",
    "    Computes normal vector of object plane\n",
    "    Args: mask (1/0) with only one object detected at the moment\n",
    "          2D image (2D vector 3 channels)\n",
    "          depth (2D vector 1 channel)\"\"\"\n",
    "    \n",
    "    # 1- Compute object coordinates\n",
    "    \n",
    "    # compute object depth by applying a mask\n",
    "    obj_depth = mask * depth\n",
    "    # compute object coordinates\n",
    "    xy_i = np.nonzero(obj_depth) #(x,y) pixels coordinates, corrected nan entries\n",
    "    nz_objdepth = obj_depth[np.nonzero(obj_depth)] #depth (z) coordinates BUT pbm with return type -> returns tuple\n",
    "    # convert in camera coordinates frame\n",
    "    \n",
    "    # convert in world coordinates frame\n",
    "    points_abs = #([x,y,z]) dim: N x 3 absolute position\n",
    "    \n",
    "    # 2- Find 3D plane\n",
    "    \n",
    "    # compute 3D plane variables and normal\n",
    "    pts = Points(points_abs) #must be built with a nd.array\n",
    "    plane = Plane.best_fit(points)\n",
    "    \n",
    "    return np.array(plane.normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Algorithm\n",
    "https://www.ilikebigbits.com/2015_03_04_plane_from_points.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Compute least squares\n",
    "    \n",
    "    # trick\n",
    "    centroid = np.sum(points_abs,axis = 0) / points_abs.shape[0]\n",
    "    points_rel = points_abs - centroid #relative position to centroid \n",
    "    # matrix coefs\n",
    "    xx = points_rel[:,0].T @ points_rel[:,0] #dim : 1 x N x N x 1 = 1\n",
    "    xy = points_rel[:,0].T @ points_rel[:,1]\n",
    "    xz = points_rel[:,0].T @ points_rel[:,2]\n",
    "    yy = points_rel[:,1].T @ points_rel[:,1]\n",
    "    yz = points_rel[:,1].T @ points_rel[:,2]\n",
    "    zz = points_rel[:,2].T @ points_rel[:,2]\n",
    "    # det calculations -> at least one of the components of the normal must be nz \n",
    "    #if the points do span a plane (which we have also to check)\n",
    "    det_x = yy*zz - yz**2\n",
    "    det_y = xx*zz - xz**2\n",
    "    det_z = xx*yy - xy**2\n",
    "    det_max = max(det_x,det_y,det_z) #keep the max\n",
    "    # check if plane\n",
    "    if abs(det_max) < 1e-9:\n",
    "        print(\"Error, no plane was found\".)\n",
    "        return None\n",
    "    # else compute plane normal vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from image to world space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_2_camera(points, depth): # TO TEST\n",
    "    \"\"\"Converts object 2D coordinates to 3D camera space coordinates\n",
    "    INTRINSIC PARAMETERS\n",
    "    Args: points (tuple)\n",
    "          depth  (single value)\n",
    "          camera object (?type)\n",
    "          \"\"\"\n",
    "    profile = self.pipeline.get_active_profile()\n",
    "    depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "    depth_intrinsics = depth_profile.get_intrinsics()\n",
    "    \n",
    "    pos = rs.rs2_deproject_pixel_to_point(depth_intrinsics, points, depth)\n",
    "    \n",
    "    return pos\n",
    "\n",
    "def camera_2_world(points, camera): #TO TEST\n",
    "    \"\"\"Converts object 3D coordinates in camera space to 3D world space coordinates\n",
    "    EXTRINSIC PARAMETERS\n",
    "    Args: points [x,y,z]\n",
    "          camera object (?type)\n",
    "          \"\"\"\n",
    "    \n",
    "    pos = rs.rs2_transform_point_to_point(\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
