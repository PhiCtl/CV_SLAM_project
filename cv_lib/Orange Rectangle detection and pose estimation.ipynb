{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skspatial.objects import Points, Plane\n",
    "from skspatial.plotting import plot_3d\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from pathlib import Path\n",
    "#import pyrealsense2 as rs\n",
    "\n",
    "def reader(name): #OK\n",
    "     #load\n",
    "    img = cv2.imread(name)\n",
    "    return img\n",
    "\n",
    "# Read img\n",
    "img_name = \"../data/Several_obj.jpg\"\n",
    "depth_name = \"../data/2_Depth.raw\"\n",
    "img = reader(img_name)\n",
    "\n",
    "# Camera metadata\n",
    "Fx = 446.866119 # Fy = Fx\n",
    "PPx = 319.154602\n",
    "PPy = 182.141769\n",
    "# distorsion = brown conrady\n",
    "\n",
    "P_in = [[Fx, 0, PPx],[0, Fx, PPy],[0,0,1]]\n",
    "\n",
    "\n",
    "# Print path\n",
    "#print(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img, sens = 10, it = 1, scale = 1, plot = False): #OK\n",
    "    \n",
    "    \"\"\"Finds object(several to handle to be defined) in frame\n",
    "    args: image from which we build the mask\n",
    "          sensitivity of color range\n",
    "          scale of picture\n",
    "          plot resulting mask\"\"\"\n",
    "    \n",
    "    # Smoothen\n",
    "    img = cv2.medianBlur(img,5)\n",
    "\n",
    "    # Resize\n",
    "    new_height = int(img.shape[0]*scale)\n",
    "    new_width  = int(img.shape[1]*scale)\n",
    "    img = cv2.resize(img, (new_width, new_height),interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Define HBR orange color range for thresholding\n",
    "    low_orange = np.array([0.153/2*180-sens,0.5*256,0.5*256], dtype = np.float32)\n",
    "    upp_orange = np.array([0.153/2*180 +sens,255,255], dtype = np.float32)\n",
    "    \n",
    "    # Opening to get rid of the small background artifacts -> TODO : tune size of opening element\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    \n",
    "    # From bgr to hsv colorspace\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Thresholding and open\n",
    "    mask = cv2.inRange(hsv, low_orange, upp_orange)\n",
    "    mask = cv2.erode(mask,kernel,iterations = it)\n",
    "\n",
    "    if plot:\n",
    "        # Bitwise and mask and original picture\n",
    "        res = cv2.bitwise_and(img,img, mask= mask)\n",
    "        cv2.imshow('result',res)\n",
    "        cv2.imshow('mask HSV',mask)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return mask, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(img, scale = 0.5, nb_clust = 3, save = False):\n",
    "    \n",
    "    # Resize\n",
    "    new_height = int(img.shape[0]*scale)\n",
    "    new_width  = int(img.shape[1]*scale)\n",
    "    img = cv2.resize(img, (new_width, new_height),interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Kmeans\n",
    "    clust = img.reshape((-1,3))\n",
    "    clust = np.float32(clust) #should be flattened and of type float32\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10,1.0) #max iter and accuracy epsilon\n",
    "    K = nb_clust \n",
    "    ret, label, center = cv2.kmeans(clust, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    clust = res.reshape((img.shape))\n",
    "    \n",
    "    # Print\n",
    "    cv2.imshow('K-means',clust)\n",
    "    cv2.imshow('Original', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if save:\n",
    "        cv2.imwrite('../data/kmeans.jpg', clust)\n",
    "    return clust   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_m = kmeans(img, nb_clust = 6)\n",
    "#img_clust = reader('../data/kmeans.jpg')\n",
    "mask, img_blurred = get_mask(img, it= 2, sens = 10, scale = 0.5, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create trackcolourbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find centroid coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(img, mask, verbose = False): #OK\n",
    "    \"\"\"Returns centroid in image coordinates\n",
    "        Args: 2D image (3 channels RGB)\n",
    "              mask (1/0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find moments based on contours\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    threshold = 200  \n",
    "    contours = [el for el in contours if cv2.contourArea(el) > threshold]\n",
    "    cnt = contours[0]\n",
    "    M = cv2.moments(cnt)\n",
    "\n",
    "    # Find centroid\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    # Plots\n",
    "    if verbose:\n",
    "        # Centroid pixels coordinates\n",
    "        print(\"x : {}, y : {}\".format(cx,cy))\n",
    "        # Print centroid\n",
    "        cv2.circle(img, (int(cx),int(cy)), 2, 255, 2)\n",
    "        # Draw contours\n",
    "        cv2.drawContours(img, contours, -1, (255, 0, 0), 2) # image, contours, contourIdx, color, thickness\n",
    "        cv2.imshow('centroid',img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    return [cx, cy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_2(img, mask, threshold = 400, verbose = False):\n",
    "    # Pick the main objects and find its moments\n",
    "    # Find moments based on contours\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [el for el in contours if cv2.contourArea(el) > threshold]\n",
    "    for el in contours:\n",
    "        M = cv2.moments(el)\n",
    "\n",
    "        # Find centroid\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "        # Plots\n",
    "        if verbose:\n",
    "            # Centroid pixels coordinates\n",
    "            print(\"x : {}, y : {}\".format(cx,cy))\n",
    "            # Print centroid\n",
    "            cv2.circle(img, (int(cx),int(cy)), 2, 255, 2)\n",
    "            # Draw contours\n",
    "            cv2.drawContours(img, el, -1, (255, 0, 0), 2) # image, contours, contourIdx, color, thickness\n",
    "            cv2.imshow('centroid',img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_2_camera(points, mask, depth):\n",
    "    \n",
    "    # Extract centroid depth\n",
    "    x,y = points[0], points[1]\n",
    "    depth_obj = mask * depth\n",
    "    z_coo = depth_obj[x,y]\n",
    "    \n",
    "    # Convert to camera space TODO: is it correct and how do I know about the sign ?\n",
    "    cam_coo = [z_coo/Fx * (x-PPx), z_coo/Fy * (y-PPy), -z_coo]\n",
    "    print(\"Position in camera coordinates: {}\".format(cam_coo))\n",
    "    \n",
    "    return cam_coo\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : 493, y : 242\n",
      "x : 149, y : 81\n",
      "x : 387, y : 58\n"
     ]
    }
   ],
   "source": [
    "centroid_2(img_blurred, mask, threshold = 1000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : 488, y : 246\n"
     ]
    }
   ],
   "source": [
    "[cx,cy] = find_centroid(img_blurred, mask, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_coo = pixel_2_camera([cx,cy],mask, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get object orientation (3D normal vector)\n",
    "https://www.ilikebigbits.com/2015_03_04_plane_from_points.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plane_orientation(mask, img, depth): #is depth included in the image ? #TO TEST\n",
    "    \"\"\"\n",
    "    Computes normal vector of object plane\n",
    "    Args: mask (1/0) with only one object detected at the moment\n",
    "          2D image (2D vector 3 channels)\n",
    "          depth (2D vector 1 channel)\"\"\"\n",
    "    \n",
    "    # 1- Compute object coordinates\n",
    "    \n",
    "    # compute object depth by applying a mask\n",
    "    obj_depth = mask * depth\n",
    "    # compute object coordinates\n",
    "    xy_i = np.nonzero(obj_depth) #(x,y) pixels coordinates, corrected nan entries\n",
    "    nz_objdepth = obj_depth[np.nonzero(obj_depth)] #depth (z) coordinates BUT pbm with return type -> returns tuple\n",
    "    # convert in camera coordinates frame\n",
    "    \n",
    "    # convert in world coordinates frame\n",
    "    points_abs = #([x,y,z]) dim: N x 3 absolute position\n",
    "    \n",
    "    # 2- Find 3D plane\n",
    "    \n",
    "    # compute 3D plane variables and normal\n",
    "    pts = Points(points_abs) #must be built with a nd.array\n",
    "    plane = Plane.best_fit(points)\n",
    "    \n",
    "    return np.array(plane.normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Algorithm\n",
    "https://www.ilikebigbits.com/2015_03_04_plane_from_points.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Compute least squares\n",
    "    \n",
    "    # trick\n",
    "    centroid = np.sum(points_abs,axis = 0) / points_abs.shape[0]\n",
    "    points_rel = points_abs - centroid #relative position to centroid \n",
    "    # matrix coefs\n",
    "    xx = points_rel[:,0].T @ points_rel[:,0] #dim : 1 x N x N x 1 = 1\n",
    "    xy = points_rel[:,0].T @ points_rel[:,1]\n",
    "    xz = points_rel[:,0].T @ points_rel[:,2]\n",
    "    yy = points_rel[:,1].T @ points_rel[:,1]\n",
    "    yz = points_rel[:,1].T @ points_rel[:,2]\n",
    "    zz = points_rel[:,2].T @ points_rel[:,2]\n",
    "    # det calculations -> at least one of the components of the normal must be nz \n",
    "    #if the points do span a plane (which we have also to check)\n",
    "    det_x = yy*zz - yz**2\n",
    "    det_y = xx*zz - xz**2\n",
    "    det_z = xx*yy - xy**2\n",
    "    det_max = max(det_x,det_y,det_z) #keep the max\n",
    "    # check if plane\n",
    "    if abs(det_max) < 1e-9:\n",
    "        print(\"Error, no plane was found\".)\n",
    "        return None\n",
    "    # else compute plane normal vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from image to world space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_2_camera(points, depth): # TO TEST\n",
    "    \"\"\"Converts object 2D coordinates to 3D camera space coordinates\n",
    "    INTRINSIC PARAMETERS\n",
    "    Args: points (tuple)\n",
    "          depth  (single value)\n",
    "          camera object (?type)\n",
    "          \"\"\"\n",
    "    profile = self.pipeline.get_active_profile()\n",
    "    depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "    depth_intrinsics = depth_profile.get_intrinsics()\n",
    "    \n",
    "    pos = rs.rs2_deproject_pixel_to_point(depth_intrinsics, points, depth)\n",
    "    \n",
    "    return pos\n",
    "\n",
    "def camera_2_world(points, camera): #TO TEST\n",
    "    \"\"\"Converts object 3D coordinates in camera space to 3D world space coordinates\n",
    "    EXTRINSIC PARAMETERS\n",
    "    Args: points [x,y,z]\n",
    "          camera object (?type)\n",
    "          \"\"\"\n",
    "    \n",
    "    pos = rs.rs2_transform_point_to_point(\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
